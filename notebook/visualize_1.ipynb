{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# プロジェクトのルートディレクトリを指定\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), './..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_class 2\n",
      "Set partition sizes: (8, 10)\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from config.modifier import dynamically_modify_train_config\n",
    "config_paths = [\n",
    "        '../config/dataset/gen1/event_frame/single/base.yaml',\n",
    "        '../config/model/rvt_detector/rvt_frame.yaml',\n",
    "        '../config/experiment/single/train.yaml',\n",
    "    ]\n",
    "\n",
    "configs = [OmegaConf.load(path) for path in config_paths]\n",
    "merged_conf = OmegaConf.merge(*configs)\n",
    "dynamically_modify_train_config(config=merged_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 186\n",
      "valid dataset size: 1200\n",
      "rvt\n",
      "RVT\n",
      "PAFPN\n",
      "neck input channels (64, 128, 256)\n",
      "head strides (8, 16, 32)\n",
      "YOLOX-Head\n"
     ]
    }
   ],
   "source": [
    "from modules.fetch import fetch_data_module, fetch_model_module\n",
    "\n",
    "data = fetch_data_module(merged_conf)\n",
    "data.setup('fit')\n",
    "model = fetch_model_module(merged_conf)\n",
    "model.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/5nhrfybd7r1d725z2nywhzg00000gn/T/ipykernel_64976/3261947062.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RVTYOLOX(\n",
       "  (backbone): RVT(\n",
       "    (stages): ModuleList(\n",
       "      (0): RVTStage(\n",
       "        (downsample_cf2cl): ConvDownsampling_Cf2Cl(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), bias=False)\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (att_blocks): ModuleList(\n",
       "          (0): MaxVitAttentionPairCl(\n",
       "            (att_window): PartitionAttentionCl(\n",
       "              (norm1): Identity()\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "                (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "            (att_grid): PartitionAttentionCl(\n",
       "              (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "                (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (lstm): DWSConvLSTM2d(\n",
       "          (conv3x3_dws): Identity()\n",
       "          (conv1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (cell_update_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RVTStage(\n",
       "        (downsample_cf2cl): ConvDownsampling_Cf2Cl(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (att_blocks): ModuleList(\n",
       "          (0): MaxVitAttentionPairCl(\n",
       "            (att_window): PartitionAttentionCl(\n",
       "              (norm1): Identity()\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
       "                (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "            (att_grid): PartitionAttentionCl(\n",
       "              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
       "                (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (lstm): DWSConvLSTM2d(\n",
       "          (conv3x3_dws): Identity()\n",
       "          (conv1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (cell_update_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RVTStage(\n",
       "        (downsample_cf2cl): ConvDownsampling_Cf2Cl(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (att_blocks): ModuleList(\n",
       "          (0): MaxVitAttentionPairCl(\n",
       "            (att_window): PartitionAttentionCl(\n",
       "              (norm1): Identity()\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "            (att_grid): PartitionAttentionCl(\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (lstm): DWSConvLSTM2d(\n",
       "          (conv3x3_dws): Identity()\n",
       "          (conv1x1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (cell_update_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RVTStage(\n",
       "        (downsample_cf2cl): ConvDownsampling_Cf2Cl(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (att_blocks): ModuleList(\n",
       "          (0): MaxVitAttentionPairCl(\n",
       "            (att_window): PartitionAttentionCl(\n",
       "              (norm1): Identity()\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "            (att_grid): PartitionAttentionCl(\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (self_attn): SelfAttentionCl(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (ls1): LayerScale()\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Sequential(\n",
       "                    (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (1): GELU()\n",
       "                  )\n",
       "                  (1): Dropout(p=0, inplace=False)\n",
       "                  (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (ls2): LayerScale()\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (lstm): DWSConvLSTM2d(\n",
       "          (conv3x3_dws): Identity()\n",
       "          (conv1x1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (cell_update_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): PAFPN(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (lateral_conv0): BaseConv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (C3_p4): CSPLayer(\n",
       "      (conv1): BaseConv(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): BaseConv(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): BaseConv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reduce_conv1): BaseConv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (C3_p3): CSPLayer(\n",
       "      (conv1): BaseConv(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): BaseConv(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): BaseConv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): BaseConv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): BaseConv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bu_conv2): BaseConv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (C3_n3): CSPLayer(\n",
       "      (conv1): BaseConv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): BaseConv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): BaseConv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): BaseConv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bu_conv1): BaseConv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (C3_n4): CSPLayer(\n",
       "      (conv1): BaseConv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): BaseConv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): BaseConv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): BaseConv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): BaseConv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): YOLOXHead(\n",
       "    (cls_convs): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reg_convs): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): BaseConv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls_preds): ModuleList(\n",
       "      (0-2): 3 x Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (reg_preds): ModuleList(\n",
       "      (0-2): 3 x Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (obj_preds): ModuleList(\n",
       "      (0-2): 3 x Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (stems): ModuleList(\n",
       "      (0): BaseConv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): BaseConv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): BaseConv(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (l1_loss): L1Loss()\n",
       "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
       "    (iou_loss): IOUloss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "ckpt_path = '../scripts/result/gen1/rvt-t/event_frame-dt50/20241116-134504/train/epoch=49-val_AP=0.42.ckpt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "rnn_model = model.model\n",
    "rnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.yolox_utils import to_yolox, postprocess\n",
    "from functools import partial\n",
    "\n",
    "# Postprocessの設定\n",
    "post_process = partial(postprocess, num_classes=2, conf_thre=0.45, nms_thre=0.1, class_agnostic=False)\n",
    "\n",
    "# 推論モード設定\n",
    "mode = 'val'\n",
    "prev_rnn_state = None\n",
    "loop_count = 1200  # 最大ループ回数\n",
    "current_loop = 0\n",
    "\n",
    "# プロットするループ回数を指定\n",
    "plot_intervals = [250, 500, 1050]\n",
    "plot_results = {}  # プロット用に保存する辞書 {ループ回数: (画像, 推論結果)}\n",
    "\n",
    "# 色変換関数\n",
    "def change_colors(image):\n",
    "    \"\"\"\n",
    "    赤 (ONイベント) を緑に、青 (OFFイベント) を黄に、灰色 (背景) を白に変換。\n",
    "    :param image: RGB画像 (H, W, C)\n",
    "    :return: 色変換後の画像 (H, W, C)\n",
    "    \"\"\"\n",
    "    # 変換先の色\n",
    "    color_mapping = {\n",
    "        (255, 0, 0): (255, 0, 0),   # 赤 -> ピンク\n",
    "        (0, 0, 255): (0, 0, 255),   # 青 -> 水色\n",
    "        (114, 114, 114): (0, 0, 0)  # 灰色 -> 白\n",
    "    }\n",
    "    \n",
    "    # ベクトル化して色変換を効率化\n",
    "    reshaped_image = image.reshape(-1, image.shape[-1])  # 2次元に展開\n",
    "    mapped_image = np.array([color_mapping.get(tuple(pixel), tuple(pixel)) for pixel in reshaped_image])\n",
    "    return mapped_image.reshape(image.shape)\n",
    "\n",
    "# 推論時の勾配計算を無効化\n",
    "with torch.no_grad():\n",
    "    # dataloader のループ\n",
    "    for batch in data.val_dataloader():\n",
    "        if current_loop >= loop_count:  # 最大ループ回数を超えたら終了\n",
    "            break\n",
    "\n",
    "        # イベントとラベルを取得\n",
    "        events = batch['events'][:, 0].float()  # 最初のシーケンス\n",
    "        labels = batch['labels']\n",
    "\n",
    "        # ラベルを YOLOX の形式に変換\n",
    "        targets = to_yolox(labels, mode=mode)[:, 0]\n",
    "\n",
    "        # RNNモデルを使用して推論\n",
    "        outputs, state = rnn_model(events, prev_rnn_state)\n",
    "\n",
    "        # 推論結果を postprocess\n",
    "        processed_pred = post_process(outputs)\n",
    "\n",
    "        # RNNの状態を保存\n",
    "        prev_rnn_state = state\n",
    "\n",
    "        # 特定のループ回数に達したら結果を保存\n",
    "        if current_loop in plot_intervals:\n",
    "            event_image = batch['events'][0, 0].numpy()\n",
    "            event_image = np.transpose(event_image, (1, 2, 0))  # (C, H, W) -> (H, W, C)\n",
    "            plot_results[current_loop] = (event_image, processed_pred)\n",
    "\n",
    "        current_loop += 1\n",
    "\n",
    "# プロット\n",
    "for loop_num, (event_image, processed_pred) in plot_results.items():\n",
    "    # 色変換処理を適用\n",
    "    converted_image = change_colors(event_image.astype(np.uint8))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(converted_image)  # 色変換後の画像を表示\n",
    "\n",
    "    # バウンディングボックスをプロットする場合\n",
    "    if processed_pred and processed_pred[0] is not None:\n",
    "        predictions = processed_pred[0]  # (x1, y1, x2, y2, obj_conf, class_conf, class_pred)\n",
    "        for bbox in predictions:\n",
    "            x1, y1, x2, y2, obj_conf, class_conf, class_pred = bbox.numpy()\n",
    "            # バウンディングボックスを描画\n",
    "            plt.gca().add_patch(plt.Rectangle(\n",
    "                (x1, y1), x2 - x1, y2 - y1, edgecolor='yellow', facecolor='none', linewidth=5))\n",
    "            # クラスとスコアを表示\n",
    "            plt.text(x1, y1 - 5, f'Class: {int(class_pred)}, Conf: {obj_conf:.2f}', \n",
    "                     color='yellow', fontsize=10, bbox=dict(facecolor='black', alpha=0.5))\n",
    "    else:\n",
    "        print(f\"No detections found at loop {loop_num}.\")\n",
    "\n",
    "    # plt.title(f\"Output at Loop {loop_num}\")\n",
    "    plt.axis('off')\n",
    "    plt.gca().set_axis_off()  # 軸の周辺を非表示に\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # 余白を削除\n",
    "    plt.savefig(f\"dt5_{loop_num}.png\", bbox_inches='tight', pad_inches=0)  # 余白なく保存\n",
    "    plt.close()  # プロットを閉じる\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from utils.yolox_utils import to_yolox, postprocess\n",
    "# from functools import partial\n",
    "\n",
    "# # Postprocessの設定\n",
    "# post_process = partial(postprocess, num_classes=2, conf_thre=0.45, nms_thre=0.1, class_agnostic=False)\n",
    "\n",
    "# # 推論モード設定\n",
    "# mode = 'val'\n",
    "# prev_rnn_state = None\n",
    "# loop_count = 1200  # 最大ループ回数\n",
    "# current_loop = 0\n",
    "\n",
    "# # プロットするループ回数を指定\n",
    "# plot_intervals = [250, 500, 1050]\n",
    "# plot_results = {}  # プロット用に保存する辞書 {ループ回数: (画像, 推論結果)}\n",
    "\n",
    "# # 推論時の勾配計算を無効化\n",
    "# with torch.no_grad():\n",
    "#     # dataloader のループ\n",
    "#     for batch in data.val_dataloader():\n",
    "#         if current_loop >= loop_count:  # 最大ループ回数を超えたら終了\n",
    "#             break\n",
    "\n",
    "#         # イベントとラベルを取得\n",
    "#         events = batch['events'][:, 0].float()  # 最初のシーケンス\n",
    "#         labels = batch['labels']\n",
    "\n",
    "#         # ラベルを YOLOX の形式に変換\n",
    "#         targets = to_yolox(labels, mode=mode)[:, 0]\n",
    "\n",
    "#         # RNNモデルを使用して推論\n",
    "#         outputs, state = rnn_model(events, prev_rnn_state)\n",
    "\n",
    "#         # 推論結果を postprocess\n",
    "#         processed_pred = post_process(outputs)\n",
    "\n",
    "#         # RNNの状態を保存\n",
    "#         prev_rnn_state = state\n",
    "\n",
    "#         # 特定のループ回数に達したら結果を保存\n",
    "#         if current_loop in plot_intervals:\n",
    "#             event_image = batch['events'][0, 0].numpy()\n",
    "#             event_image = np.transpose(event_image, (1, 2, 0))  # (C, H, W) -> (H, W, C)\n",
    "#             plot_results[current_loop] = (event_image, processed_pred)\n",
    "\n",
    "#         current_loop += 1\n",
    "\n",
    "# # プロット\n",
    "# for loop_num, (event_image, processed_pred) in plot_results.items():\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.imshow(event_image)  # RGB画像をそのまま表示\n",
    "\n",
    "#     # バウンディングボックスをプロットする場合\n",
    "#     if processed_pred and processed_pred[0] is not None:\n",
    "#         predictions = processed_pred[0]  # (x1, y1, x2, y2, obj_conf, class_conf, class_pred)\n",
    "#         for bbox in predictions:\n",
    "#             x1, y1, x2, y2, obj_conf, class_conf, class_pred = bbox.numpy()\n",
    "#             # バウンディングボックスを描画\n",
    "#             plt.gca().add_patch(plt.Rectangle(\n",
    "#                 (x1, y1), x2 - x1, y2 - y1, edgecolor='yellow', facecolor='none', linewidth=2))\n",
    "#             # クラスとスコアを表示\n",
    "#             plt.text(x1, y1 - 5, f'Class: {int(class_pred)}, Conf: {obj_conf:.2f}', \n",
    "#                      color='yellow', fontsize=10, bbox=dict(facecolor='black', alpha=0.5))\n",
    "#     else:\n",
    "#         print(f\"No detections found at loop {loop_num}.\")\n",
    "\n",
    "#     # plt.title(f\"Output at Loop {loop_num}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.gca().set_axis_off()  # 軸の周辺を非表示に\n",
    "#     plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # 余白を削除\n",
    "#     plt.savefig(f\"dt100_{loop_num}.png\", bbox_inches='tight', pad_inches=0)  # 余白なく保存\n",
    "#     plt.close()  # プロットを閉じる\n",
    "#     # plt.axis('off')\n",
    "#     # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from utils.yolox_utils import to_yolox, postprocess\n",
    "# from functools import partial\n",
    "\n",
    "# # Postprocessの設定\n",
    "# post_process = partial(postprocess, num_classes=2, conf_thre=0.45, nms_thre=0.1, class_agnostic=False)\n",
    "\n",
    "# # 推論モード設定\n",
    "# mode = 'val'\n",
    "# prev_rnn_state = None\n",
    "# loop_count = 500  # ループ回数を指定\n",
    "# current_loop = 0\n",
    "# final_batch = None\n",
    "# final_processed_pred = None\n",
    "\n",
    "# # 推論時の勾配計算を無効化\n",
    "# with torch.no_grad():\n",
    "#     # dataloader のループ\n",
    "#     for batch in data.val_dataloader():\n",
    "#         if current_loop >= loop_count:  # 指定した回数に達したら終了\n",
    "#             break\n",
    "\n",
    "#         # イベントとラベルを取得\n",
    "#         events = batch['events'][:, 0].float()  # 最初のシーケンス\n",
    "#         labels = batch['labels']\n",
    "\n",
    "#         # ラベルを YOLOX の形式に変換\n",
    "#         targets = to_yolox(labels, mode=mode)[:, 0]\n",
    "\n",
    "#         # RNNモデルを使用して推論\n",
    "#         outputs, state = rnn_model(events, prev_rnn_state)\n",
    "\n",
    "#         # 推論結果を postprocess\n",
    "#         processed_pred = post_process(outputs)\n",
    "\n",
    "#         # RNNの状態を保存\n",
    "#         prev_rnn_state = state\n",
    "\n",
    "#         # 最後のループのバッチと推論結果を保存\n",
    "#         final_batch = batch\n",
    "#         final_processed_pred = processed_pred\n",
    "\n",
    "#         current_loop += 1\n",
    "\n",
    "# # 最後の画像をプロット\n",
    "# event_image = final_batch['events'][0, 0].numpy()  # 計算グラフがないのでそのまま numpy() 使用可能\n",
    "# event_image = np.transpose(event_image, (1, 2, 0))  # (C, H, W) -> (H, W, C) に変換\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(event_image)  # RGB画像をそのまま表示\n",
    "\n",
    "# # バウンディングボックスをプロットする場合\n",
    "# if final_processed_pred and final_processed_pred[0] is not None:\n",
    "#     predictions = final_processed_pred[0]  # (x1, y1, x2, y2, obj_conf, class_conf, class_pred)\n",
    "#     for bbox in predictions:\n",
    "#         # そのまま numpy() 使用\n",
    "#         x1, y1, x2, y2, obj_conf, class_conf, class_pred = bbox.numpy()\n",
    "#         # バウンディングボックスを描画\n",
    "#         plt.gca().add_patch(plt.Rectangle(\n",
    "#             (x1, y1), x2 - x1, y2 - y1, edgecolor='yellow', facecolor='none', linewidth=2))\n",
    "#         # クラスとスコアを表示\n",
    "#         plt.text(x1, y1 - 5, f'Class: {int(class_pred)}, Conf: {obj_conf:.2f}', \n",
    "#                  color='yellow', fontsize=10, bbox=dict(facecolor='black', alpha=0.5))\n",
    "# else:\n",
    "#     print(\"No detections found in the final loop.\")\n",
    "\n",
    "# plt.title(\"Final Output After 100 Loops\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
